# -*- coding: utf-8 -*-
"""WeatherForecasting-NeuralProphet-Safe-TakeOff.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ct_p2cCt7xu8bQvaijwt1-W1-Mqerm2t

# <a>Import libraries</a>
"""



import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, datetime, timedelta, date
import seaborn as sns
from neuralprophet import NeuralProphet
import warnings
warnings.filterwarnings('ignore')

"""# <a>Pre-processing</a>"""

df = pd.read_csv("datasets/weather_data.csv")

df['time_stamp'] = pd.to_datetime(df['time_stamp'])
df.set_index('time_stamp')

df.info()

df.describe

temp_smooth = df.temperature.rolling(window=24).mean()
temp_smooth.isnull().sum()

temp = df.drop('time_stamp', axis=1)
fig, axes = plt.subplots(4, 2, figsize=(20, 30))
i = 0
for column in temp:
  sns.kdeplot(temp[column], ax=axes[i//2][i%2])
  i += 1

temp = df.drop('time_stamp', axis=1)
fig, axes = plt.subplots(4, 2, figsize=(20, 30))
i = 0
for column in temp:
  sns.boxplot(temp[column], ax=axes[i//2][i%2])
  i += 1

df['date'] = df['time_stamp'].dt.date
df['year'] = df['time_stamp'].dt.year
df['month'] = df['time_stamp'].dt.month

df.corr()

def show_heatmap(data):
    plt.figure(figsize=(15,15)) 
    plt.matshow(data.corr(), fignum=1)
    plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=90)
    plt.gca().xaxis.tick_bottom()
    plt.yticks(range(data.shape[1]), data.columns, fontsize=14)

    cb = plt.colorbar()
    cb.ax.tick_params(labelsize=14)
    plt.title("Feature Correlation Heatmap", fontsize=14)
    plt.show()

df2 = df[['temperature','dewpoint_temperature','wind_speed','mean_sea_level_pressure','relative_humidity','surface_solar_radiation','surface_thermal_radiation','total_cloud_cover']]
show_heatmap(df2)

temp_smooth.plot(figsize=(20,15))
print('Hello',1)

from statsmodels.tsa.seasonal import seasonal_decompose

temp_add_decomp = seasonal_decompose(df.temperature, model='multiplicative', extrapolate_trend='freq', period=365*24)

plt.rcParams.update({'figure.figsize':(20,20)})
temp_add_decomp.plot().suptitle('Additive decomposition of temperature', fontsize=22)
plt.show()

df1 = df[df['date'] >= date(2017,1,1)]
dfbefore2021 = df[df['year']<2021]

"""# <a>Temperature</a>

"""
print('Hello',2)


df = pd.read_csv("datasets/weather_data.csv")[['time_stamp', 'temperature']]
df.time_stamp = pd.to_datetime(df.time_stamp)

avgtemp = pd.DataFrame(df1.groupby(['date'])['temperature'].mean())
temp_add = seasonal_decompose(avgtemp['temperature'], model='additive',extrapolate_trend='freq',period=365)

plt.rcParams.update({'figure.figsize':(20,15)})
temp_add.plot().suptitle('Additive Decomposition', fontsize=22)
plt.show()

yearlytemp = pd.DataFrame(dfbefore2021.groupby(['year'])['temperature'].mean())
plt.plot(yearlytemp.index, yearlytemp.temperature, color='tab:brown',marker='o') #
plt.gca().set(title='Average Yearly Temperature',xlabel='Year',ylabel='Degree Celcius')
plt.show()
print('Hello',3)

df.rename(columns = {'time_stamp':'ds', 'temperature':'y'}, inplace = True)

"""### Hyper Parameter Tuning """
"""
split_date = '2020-12-31 00:00:00'
train_df = weather_df.loc[weather_df.index <= split_date].copy()
test_df = weather_df.loc[weather_df.index > split_date].copy()

from sklearn.model_selection import ParameterGrid
params_grid = {'seasonality_mode':('multiplicative','additive'),
               'changepoint_prior_scale':[0.1,0.2,0.3,0.4,0.5],
              'n_changepoints' : [100,150,200]}
grid = ParameterGrid(params_grid)
cnt = 0
for p in grid:
    cnt = cnt+1

print('Total Possible Models',cnt)

strt='2020-12-31 00:00:00'
end='2021-06-01 00:00:00'
model_parameters = pd.DataFrame(columns = ['MAPE','Parameters'])
for p in grid:
    test = pd.DataFrame()
    print(p)
    random.seed(0)
    train_model =NeuralProphet(changepoint_prior_scale = p['changepoint_prior_scale'],
                         n_changepoints = p['n_changepoints'],
                         seasonality_mode = p['seasonality_mode'],
                         weekly_seasonality=True,
                         daily_seasonality = True,
                         yearly_seasonality = True,
                         interval_width=0.95)
    train_model.fit(train_df)
    train_forecast = train_model.make_future_dataframe(periods=57, freq='D',include_history = False)
    train_forecast = train_model.predict(train_forecast)
    test=train_forecast[['ds','yhat']]
    Actual = df[(df['ds']>strt) & (df['ds']<=end)]
    MAPE = mean_absolute_percentage_error(Actual['y'],abs(test['yhat']))
    print('Mean Absolute Percentage Error(MAPE)------------------------------------',MAPE)
    model_parameters = model_parameters.append({'MAPE':MAPE,'Parameters':p},ignore_index=True)

parameters = model_parameters.sort_values(by=['MAPE'])
parameters = parameters.reset_index(drop=True)
parameters.head()

parameters['Parameters'][0]
"""

"""### Model"""

print('Hello',4)


m = NeuralProphet(changepoints_range=0.95, 
                  n_changepoints=50, 
                  trend_reg=1, 
                  weekly_seasonality=False, 
                  daily_seasonality=10, 
                  yearly_seasonality=10)

df['ds'] = pd.DatetimeIndex(df['ds'])
df.head()

df_train, df_val = m.split_df(df, freq='H', valid_p = 0.2)
metrics = m.fit(df_train, freq='H', validation_df=df_val)

seasonal_components = m.predict_seasonal_components(df)
seasonal_components

metrics

fig, ax = plt.subplots(figsize=(20, 8))
ax.plot(metrics["MAE"], '-o', label="Training Loss")  
ax.plot(metrics["MAE_val"], '-r', label="Validation Loss")
ax.legend(loc='center right', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=20)
ax.set_xlabel("Epoch", fontsize=28)
ax.set_ylabel("Loss", fontsize=28)
ax.set_title("Model Loss (MAE)", fontsize=28)

future = m.make_future_dataframe(df, periods=24*365*2, n_historic_predictions=len(df))
future.tail()

forecast = m.predict(future)

forecast

forecast_df = forecast.copy()
forecast_df.info()

df.info()

component_plot = m.plot_components(forecast)
# plt.show(component_plot)

m.predict_trend(df)

forecast_plot = m.plot(forecast)
plt.show()

forecast.to_csv( "temperature_prediction.csv", index=False)
print("hello")
"""# <a>Wind Speed</a>"""

df = pd.read_csv("datasets/weather_data.csv")[['time_stamp', 'wind_speed']]

df.time_stamp = pd.to_datetime(df.time_stamp)

avgwindspeed = pd.DataFrame(df1.groupby(['date'])['wind_speed'].mean())
windspeed_add = seasonal_decompose(avgwindspeed['wind_speed'], model='additive',extrapolate_trend='freq',period=365)

plt.rcParams.update({'figure.figsize':(20,15)})
windspeed_add.plot().suptitle('Additive Decomposition', fontsize=22)
plt.show()

monthlywind = pd.DataFrame(dfbefore2021.groupby(['month'])['wind_speed'].mean())
months=['January','February','March','April','May','June','July','August','Sepetember','October','November','December']
monthlywind['Month']=months
plt.plot(monthlywind.Month, monthlywind.wind_speed, color='tab:red',marker='o') #
plt.gca().set(title='Average Monthly Wind Speed',xlabel='Month',ylabel='kmph')
plt.show()

df.rename(columns = {'time_stamp':'ds', 'wind_speed':'y'}, inplace = True)

"""### Hyper Parameter Tuning """
"""
split_date = '2020-12-31 00:00:00'
train_df = weather_df.loc[weather_df.index <= split_date].copy()
test_df = weather_df.loc[weather_df.index > split_date].copy()

from sklearn.model_selection import ParameterGrid
params_grid = {'seasonality_mode':('multiplicative','additive'),
               'changepoint_prior_scale':[0.1,0.2,0.3,0.4,0.5],
              'n_changepoints' : [100,150,200]}
grid = ParameterGrid(params_grid)
cnt = 0
for p in grid:
    cnt = cnt+1

print('Total Possible Models',cnt)

strt='2020-12-31 00:00:00'
end='2021-06-01 00:00:00'
model_parameters = pd.DataFrame(columns = ['MAPE','Parameters'])
for p in grid:
    test = pd.DataFrame()
    print(p)
    random.seed(0)
    train_model =NeuralProphet(changepoint_prior_scale = p['changepoint_prior_scale'],
                         n_changepoints = p['n_changepoints'],
                         seasonality_mode = p['seasonality_mode'],
                         weekly_seasonality=True,
                         daily_seasonality = True,
                         yearly_seasonality = True,
                         interval_width=0.95)
    train_model.fit(train_df)
    train_forecast = train_model.make_future_dataframe(periods=57, freq='D',include_history = False)
    train_forecast = train_model.predict(train_forecast)
    test=train_forecast[['ds','yhat']]
    Actual = df[(df['ds']>strt) & (df['ds']<=end)]
    MAPE = mean_absolute_percentage_error(Actual['y'],abs(test['yhat']))
    print('Mean Absolute Percentage Error(MAPE)------------------------------------',MAPE)
    model_parameters = model_parameters.append({'MAPE':MAPE,'Parameters':p},ignore_index=True)

parameters = model_parameters.sort_values(by=['MAPE'])
parameters = parameters.reset_index(drop=True)
parameters.head()

parameters['Parameters'][0]
"""
"""## Model"""

m = NeuralProphet(changepoints_range=0.95, 
                  n_changepoints=50, 
                  trend_reg=1, 
                  weekly_seasonality=False, 
                  daily_seasonality=10, 
                  yearly_seasonality=10)

df['ds'] = pd.DatetimeIndex(df['ds'])
df.head()

m = NeuralProphet(changepoints_range=0.95, n_changepoints=50, trend_reg=1, weekly_seasonality=False, daily_seasonality=10)
df_train, df_val = m.split_df(df, freq='H', valid_p = 0.2)
metrics = m.fit(df_train, freq='H', validation_df=df_val)

metrics

fig, ax = plt.subplots(figsize=(20, 8))
ax.plot(metrics["MAE"], '-o', label="Training Loss")  
ax.plot(metrics["MAE_val"], '-r', label="Validation Loss")
ax.legend(loc='center right', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=20)
ax.set_xlabel("Epoch", fontsize=28)
ax.set_ylabel("Loss", fontsize=28)
ax.set_title("Model Loss (MAE)", fontsize=28)

future = m.make_future_dataframe(df, periods=24*365*2, n_historic_predictions=len(df))
forecast = m.predict(future)

forecast

m.plot_components(forecast)
plt.show()

forecast_plot = m.plot(forecast)
plt.show()

forecast.to_csv( "windspeed_prediction.csv", index=False)

"""# <a>Pressure</a>"""

df = pd.read_csv("datasets/weather_data.csv")[['time_stamp', 'mean_sea_level_pressure']]
df.time_stamp = pd.to_datetime(df.time_stamp)

avgpressure = pd.DataFrame(df1.groupby(['date'])['mean_sea_level_pressure'].mean())
pressure_add = seasonal_decompose(avgpressure['mean_sea_level_pressure'], model='additive',extrapolate_trend='freq',period=365)

plt.rcParams.update({'figure.figsize':(20,15)})
pressure_add.plot().suptitle('Additive Decomposition', fontsize=22)
plt.show()

monthlypressure = pd.DataFrame(dfbefore2021.groupby(['month'])['mean_sea_level_pressure'].mean())
months=['January','February','March','April','May','June','July','August','Sepetember','October','November','December']
monthlypressure['Month']=months
plt.plot(monthlypressure.Month, monthlypressure.mean_sea_level_pressure, color='tab:red',marker='o') #
plt.gca().set(title='Average Monthly Pressure',xlabel='Month',ylabel='kmph')
plt.show()

df.rename(columns = {'time_stamp':'ds', 'mean_sea_level_pressure':'y'}, inplace = True)

df['ds'] = pd.DatetimeIndex(df['ds'])
df.head()



"""### Hyper Parameter Tuning """
"""
split_date = '2020-12-31 00:00:00'
train_df = weather_df.loc[weather_df.index <= split_date].copy()
test_df = weather_df.loc[weather_df.index > split_date].copy()

from sklearn.model_selection import ParameterGrid
params_grid = {'seasonality_mode':('multiplicative','additive'),
               'changepoint_prior_scale':[0.1,0.2,0.3,0.4,0.5],
              'n_changepoints' : [100,150,200]}
grid = ParameterGrid(params_grid)
cnt = 0
for p in grid:
    cnt = cnt+1

print('Total Possible Models',cnt)

strt='2020-12-31 00:00:00'
end='2021-06-01 00:00:00'
model_parameters = pd.DataFrame(columns = ['MAPE','Parameters'])
for p in grid:
    test = pd.DataFrame()
    print(p)
    random.seed(0)
    train_model =NeuralProphet(changepoint_prior_scale = p['changepoint_prior_scale'],
                         n_changepoints = p['n_changepoints'],
                         seasonality_mode = p['seasonality_mode'],
                         weekly_seasonality=True,
                         daily_seasonality = True,
                         yearly_seasonality = True,
                         interval_width=0.95)
    train_model.fit(train_df)
    train_forecast = train_model.make_future_dataframe(periods=57, freq='D',include_history = False)
    train_forecast = train_model.predict(train_forecast)
    test=train_forecast[['ds','yhat']]
    Actual = df[(df['ds']>strt) & (df['ds']<=end)]
    MAPE = mean_absolute_percentage_error(Actual['y'],abs(test['yhat']))
    print('Mean Absolute Percentage Error(MAPE)------------------------------------',MAPE)
    model_parameters = model_parameters.append({'MAPE':MAPE,'Parameters':p},ignore_index=True)

parameters = model_parameters.sort_values(by=['MAPE'])
parameters = parameters.reset_index(drop=True)
parameters.head()

parameters['Parameters'][0]
"""
"""## Model"""

m = NeuralProphet(changepoints_range=0.95, 
                  n_changepoints=50, 
                  trend_reg=1, 
                  weekly_seasonality=False, 
                  daily_seasonality=10, 
                  yearly_seasonality=10)

df_train, df_val = m.split_df(df, freq='H', valid_p = 0.2)
metrics = m.fit(df_train, freq='H', validation_df=df_val)

metrics

fig, ax = plt.subplots(figsize=(20, 8))
ax.plot(metrics["MAE"], '-o', label="Training Loss")  
ax.plot(metrics["MAE_val"], '-r', label="Validation Loss")
ax.legend(loc='center right', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=20)
ax.set_xlabel("Epoch", fontsize=28)
ax.set_ylabel("Loss", fontsize=28)
ax.set_title("Model Loss (MAE)", fontsize=28)

future = m.make_future_dataframe(df, periods=24*365*2, n_historic_predictions=len(df))
forecast = m.predict(future)

forecast

m.plot_components(forecast)
plt.show()

forecast_plot = m.plot(forecast)
plt.show()

forecast.to_csv( "pressure_prediction.csv", index=False)

"""# <a>Total Cloud Cover</a>"""

df = pd.read_csv("datasets/weather_data.csv")[['time_stamp', 'total_cloud_cover']]
df.time_stamp = pd.to_datetime(df.time_stamp)

avgcloud = pd.DataFrame(df1.groupby(['date'])['total_cloud_cover'].mean())
cloud_add = seasonal_decompose(avgcloud['total_cloud_cover'], model='additive',extrapolate_trend='freq',period=365)

plt.rcParams.update({'figure.figsize':(20,15)})
cloud_add.plot().suptitle('Additive Decomposition', fontsize=22)
plt.show()

monthlycloud = pd.DataFrame(dfbefore2021.groupby(['month'])['total_cloud_cover'].mean())
months=['January','February','March','April','May','June','July','August','Sepetember','October','November','December']
monthlycloud['Month']=months
plt.plot(monthlycloud.Month, monthlycloud.total_cloud_cover, color='tab:red',marker='o') #
plt.gca().set(title='Average Monthly Total Cloud Cover',xlabel='Month')
plt.show()

df.rename(columns = {'time_stamp':'ds', 'total_cloud_cover':'y'}, inplace = True)

df['ds'] = pd.DatetimeIndex(df['ds'])
df.head()

"""### Hyper Parameter Tuning """
"""
split_date = '2020-12-31 00:00:00'
train_df = weather_df.loc[weather_df.index <= split_date].copy()
test_df = weather_df.loc[weather_df.index > split_date].copy()

from sklearn.model_selection import ParameterGrid
params_grid = {'seasonality_mode':('multiplicative','additive'),
               'changepoint_prior_scale':[0.1,0.2,0.3,0.4,0.5],
              'n_changepoints' : [100,150,200]}
grid = ParameterGrid(params_grid)
cnt = 0
for p in grid:
    cnt = cnt+1

print('Total Possible Models',cnt)

strt='2020-12-31 00:00:00'
end='2021-06-01 00:00:00'
model_parameters = pd.DataFrame(columns = ['MAPE','Parameters'])
for p in grid:
    test = pd.DataFrame()
    print(p)
    random.seed(0)
    train_model =NeuralProphet(changepoint_prior_scale = p['changepoint_prior_scale'],
                         n_changepoints = p['n_changepoints'],
                         seasonality_mode = p['seasonality_mode'],
                         weekly_seasonality=True,
                         daily_seasonality = True,
                         yearly_seasonality = True,
                         interval_width=0.95)
    train_model.fit(train_df)
    train_forecast = train_model.make_future_dataframe(periods=57, freq='D',include_history = False)
    train_forecast = train_model.predict(train_forecast)
    test=train_forecast[['ds','yhat']]
    Actual = df[(df['ds']>strt) & (df['ds']<=end)]
    MAPE = mean_absolute_percentage_error(Actual['y'],abs(test['yhat']))
    print('Mean Absolute Percentage Error(MAPE)------------------------------------',MAPE)
    model_parameters = model_parameters.append({'MAPE':MAPE,'Parameters':p},ignore_index=True)

parameters = model_parameters.sort_values(by=['MAPE'])
parameters = parameters.reset_index(drop=True)
parameters.head()

parameters['Parameters'][0]
"""
"""## Model"""

m = NeuralProphet(changepoints_range=0.95, 
                  n_changepoints=50, 
                  trend_reg=1, 
                  weekly_seasonality=False, 
                  daily_seasonality=10, 
                  yearly_seasonality=10)

df_train, df_val = m.split_df(df, freq='H', valid_p = 0.2)
metrics = m.fit(df_train, freq='H', validation_df=df_val)

metrics

fig, ax = plt.subplots(figsize=(20, 8))
ax.plot(metrics["MAE"], '-o', label="Training Loss")  
ax.plot(metrics["MAE_val"], '-r', label="Validation Loss")
ax.legend(loc='center right', fontsize=16)
ax.tick_params(axis='both', which='major', labelsize=20)
ax.set_xlabel("Epoch", fontsize=28)
ax.set_ylabel("Loss", fontsize=28)
ax.set_title("Model Loss (MAE)", fontsize=28)

future = m.make_future_dataframe(df, periods=24*365*2, n_historic_predictions=len(df))
forecast = m.predict(future)

forecast

m.plot_components(forecast)
plt.show()

forecast_plot = m.plot(forecast)
plt.show()

forecast.to_csv( "cloudcover_prediction.csv", index=False)

temp= pd.read_csv('temperature_prediction.csv')
cloudcover= pd.read_csv('cloudcover_prediction.csv')
pressure= pd.read_csv('pressure_prediction.csv')
wind= pd.read_csv('windspeed_prediction.csv')

new= temp["ds"].str.split(" ", n = 1, expand = True)
temp['datestamp'] = pd.to_datetime(temp['ds'])
temp['date'] = new[0]
temp['time'] = new[1]
temp['hour'] = temp['datestamp'].dt.hour

new= cloudcover["ds"].str.split(" ", n = 1, expand = True)
cloudcover['datestamp'] = pd.to_datetime(cloudcover['ds'])
cloudcover['date'] = new[0]
cloudcover['time'] = new[1]
cloudcover['hour'] = cloudcover['datestamp'].dt.hour
cloudcover['date'] = new[0]
cloudcover['time'] = new[1]

new= wind["ds"].str.split(" ", n = 1, expand = True)
wind['datestamp'] = pd.to_datetime(wind['ds'])
wind['date'] = new[0]
wind['time'] = new[1]
wind['hour'] = wind['datestamp'].dt.hour
wind['date'] = new[0]
wind['time'] = new[1]

new= pressure["ds"].str.split(" ", n = 1, expand = True)
pressure['datestamp'] = pd.to_datetime(pressure['ds'])
pressure['date'] = new[0]
pressure['time'] = new[1]
pressure['hour'] = pressure['datestamp'].dt.hour
pressure['date'] = new[0]
pressure['date'] = new[1]

final =pd.DataFrame()

final['datestamp'] = temp['datestamp']
final['date'] = temp['date']
final['time'] = temp['time']
final['hour'] = temp['hour']
final['temperature'] = temp['yhat1']
final['windspeed'] = wind['yhat1']
final['pressure'] = pressure['yhat1']
final['cloudcover'] = cloudcover['yhat1']

final.to_csv('allpredicted2.csv',index=False)

